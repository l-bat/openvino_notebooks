# Visual Question Answering and Image Captioning using BLIP and OpenVINO
[BLIP](https://arxiv.org/abs/2201.12086) is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks.
This tutorial considers ways to use BLIP for visual question answering and image captioning.

The complete pipeline of this demo is shown below:

## Image Captioning

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221865836-a56da06e-196d-449c-a5dc-4136da6ab5d5.png"/>
</p>

The following image shows an example of the input image and generated caption:

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221933471-5c06cc51-073c-48af-b514-bddce1a89aaa.png"/>
</p>

## Visual Question Answering

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221868167-d0081add-d9f3-4591-80e7-4753c88c1d0a.png"/>
</p>
The following image shows an example of the input image, question and answer generated by model

<p align="center">
    <img src="https://user-images.githubusercontent.com/29454499/221933762-4ff32ecb-5e5d-4484-80e1-e9396cb3c511.png"/>
</p>


## Notebook Contents

This folder contains two notebooks that show how to convert and quantize model with OpenVINO:

1. [Convert the BLIP model using OpenVINO](233-blip-visual-language-processing.ipynb)
2. [Quantize the OpenVINO BLIP model using NNCF](233-blip-quantize-nncf.ipynb)

The 1st notebook  consists of the following parts:

1. Instantiate a BLIP model.
2. Convert the BLIP model to OpenVINO IR.
3. Run visual question answering and image captioning with OpenVINO.

The 2nd notebook  consists of the following parts:

1. Download and preprocess dataset for quantization.
2. Quantize the converted OpenVINO models from [1st notebook](233-blip-visual-language-processing.ipynb) with NNCF.
3. Check the model result using the same input data from the [1st notebook](233-blip-visual-language-processing.ipynb).
4. Compare model size of converted and quantized models.
5. Compare performance of converted and quantized models.

NNCF performs quantization within the OpenVINO IR. It is required to run the 1st notebook before running the 2nd notebook.

## Installation Instructions

This is a self-contained example that relies solely on its own code.</br>
We recommend running the notebook in a virtual environment. You only need a Jupyter server to start.
For details, please refer to [Installation Guide](../../README.md).
